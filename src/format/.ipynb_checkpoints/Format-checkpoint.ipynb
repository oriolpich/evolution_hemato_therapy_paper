{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data after running Sarek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from formatting import process_strelka_calling\n",
    "\n",
    "sys.path.append(\"../config\")\n",
    "from config import DIR_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to create the following mappable file, do this:\n",
    "```\n",
    "get the file from https://github.com/Boyle-Lab/Blacklist/blob/master/lists/hg38-blacklist.v2.bed.gz\n",
    "\n",
    "zcat hg38-blacklist.v2.bed.gz | cut -f1,2,3 > hg38_kundaje.bed\n",
    "\n",
    "# how to get the low complexity regions is explained in the mutational footprints of cancer therapies repo\n",
    "zcat hg38.low_complexity_ucsc.gz | cut -f1,2,3 > hg38_ucsc.bed\n",
    "cat  hg38_kundaje.bed hg38_ucsc.bed | sort -k1,1 -k2,2n > hg38_unmappable_ucsc_kundaje.bed\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download this files and modify the paths\n",
    "path_mappable = '/workspace/projects/reverse_calling/src/mappability/hg38_unmappable_ucsc_kundaje.bed'\n",
    "file_gnomad = '/workspace/datasets/gnomad/gnomad.genomes.r2.0.1.sites.GRCh38.noVEP.vcf.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----\n",
    "# Example on how to process dbGAP SAMPLES. The WTSI and inhouse samples have to be processed in the same way\n",
    "#-----\n",
    "\n",
    "# Path where Sarek calling is located\n",
    "path_sarek_AML = \"/workspace/datasets/reverse_calling/AML_Sequencing_Project/phs000159/test/calling_primary/*/*/sarek/VariantCalling/*/Strelka/StrelkaBP_*_somatic_snvs.vcf.gz\"\n",
    "path_sarek_AML2 = \"/workspace/datasets/reverse_calling/AML_Sequencing_Project/phs000159/test/calling/*/*/sarek/VariantCalling/*/Strelka/StrelkaBP_*_somatic_snvs.vcf.gz\"\n",
    "\n",
    "# Location results\n",
    "final_outpath = DIR_SAMPLES\n",
    "\n",
    "# info about the SRA run table that you get in dbGAP\n",
    "sra_run_table1 = '/workspace/datasets/reverse_calling/AML_Sequencing_Project/phs000159/test/run_info_table/SraRunTable_DS-HEM.txt'\n",
    "df_hem = pd.read_csv(sra_run_table1, sep =',',  comment='#')\n",
    "\n",
    "sra_run_table2 = '/workspace/datasets/reverse_calling/AML_Sequencing_Project/phs000159/test/run_info_table/SraRunTable_GRU.txt'\n",
    "df_gru = pd.read_csv(sra_run_table2, sep =',',  comment='#')\n",
    "\n",
    "\n",
    "df = pd.concat([df_hem, df_gru], sort = False)\n",
    "dic_sex = {'male':'MALE', 'female':'FEMALE'}\n",
    "    \n",
    "# Files tAML\n",
    "files = glob(path_sarek_AML) + glob(path_sarek_AML2)\n",
    "\n",
    "for f in files:\n",
    "    patient = f.split('/')[-7]\n",
    "    sex_patient = dic_sex.get(df[df['submitted_subject_id']==patient]['sex'].tolist()[0], 'FEMALE') \n",
    "    \n",
    "    # do processing\n",
    "    process_strelka_calling(f, sex_patient, final_outpath, path_mappable, file_gnomad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary with equivalences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate the needed dictionaries for annotations. Fix the paths accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "python make_list_ttypes.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from config import LIST_TTYPE, ALL_MUTS\n",
    "\n",
    "# these will parse all the formatted samples. Remember to change the paths in the config file\n",
    "all_files = glob(\"{}*.muts.gz\".format(final_outpath))\n",
    "all_f = []\n",
    "\n",
    "for f in all_files:\n",
    "    df = pd.read_csv(f, sep ='\\t')\n",
    "    all_f.append(df)\n",
    "    \n",
    "mixed = pd.concat(all_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_gnomad =15708\n",
    "filter_samples = round(0.001*total_gnomad)\n",
    "\n",
    "# Remove variants with high prevalence in gnomad\n",
    "filtered_gnomad = mixed[mixed['gnomAD']<filter_samples]\n",
    "filtered_gnomad[\"ID\"] = filtered_gnomad.apply(lambda x : '{}_{}_{}_{}'.format(x['CHROM'],x['POS'],\n",
    "                                                                              x['REF'], x['ALT']), axis = 1)\n",
    "filtered_gnomad = filtered_gnomad.drop_duplicates('ID')\n",
    "\n",
    "# Hypermutants, mostly with artefactual signatures\n",
    "remove_hypermuts = ['SRR529407_SRR529654',\n",
    "                    'SRR529701_SRR529455', \n",
    "                    'SRR529209_SRR529350',\n",
    "                    'SRR528853_SRR529571']\n",
    "\n",
    "# Filter by reads supporting the variant and excluding hypermutants\n",
    "t = filtered_gnomad[(filtered_gnomad['TOTAL_READS']>=5)&\n",
    "                    (filtered_gnomad['VAR_COUNTS']>2)&\n",
    "                    (~filtered_gnomad['SAMPLE'].isin(remove_hypermuts))]\n",
    "\n",
    "\n",
    "# Add ttype-label to samples\n",
    "dic_ttype = json.load(open(LIST_TTYPE))\n",
    "dic_total = {}\n",
    "for ttype, samples in dic_ttype.items():\n",
    "    for sample in samples:\n",
    "        dic_total[sample] = ttype\n",
    "        \n",
    "t['TTYPE'] = t['SAMPLE'].map(dic_total)\n",
    "wanted_ttypes = ['primary', 'tAML', 'relapse']\n",
    "t = t[t['TTYPE'].isin(wanted_ttypes)]\n",
    "\n",
    "# Save results\n",
    "t.to_csv(ALL_MUTS, sep ='\\t', \n",
    "            index = False, header = True, compression = 'gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
